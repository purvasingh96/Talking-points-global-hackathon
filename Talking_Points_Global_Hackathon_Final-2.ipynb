{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Talking_Points_Global_Hackathon_Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC8443f7s6Gl",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Network\n",
        "\n",
        "Some applications of deep-learning involve temporal-dependencies i.e. dependencies over time i.e. not just on current input but also on past inputs. RNNs are similar to feed-forward networks but in addition to *memory*.<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/RNNs%20-%20Temporal%20Dependencies.png?raw=1\" width=\"300\" height=\"40%\"></img>\n",
        "\n",
        "In RNNs, the current output *y* depends not only on current input *x*, but also on memory element *s*, that takes into account past inputs. \n",
        "\n",
        "RNNs also attempt to address the need of capturing information in previous inputs by maintaining internal memory elements called *States.*<br><br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/RNNs-%20States.png?raw=1\" width=\"300\"></img>\n",
        "\n",
        "## Applications of RNNs\n",
        "\n",
        "1. Some of the applications of RNN requires predicting the next word in the sentence which requires looking at *last few words instead of the current one.*\n",
        "\n",
        "2. Sentiment Analysis\n",
        "3. Speech Recognition\n",
        "4. Time Series Prediction\n",
        "5. NLP\n",
        "6. Gesture Recognition\n",
        "\n",
        "## Structure of RNNs\n",
        "Below are the folded and unfolded sructure of RNNs - <br>\n",
        "\n",
        "| Folded RNN                                                    | Un-folded RNN                                               |\n",
        "|---------------------------------------------------------------|-------------------------------------------------------------|\n",
        "| <img  src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/RNN-%20Folded%20Model.png?raw=1\" width=\"500\"></img> | <img  src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/RNNs%20-%20Unfolded.png?raw=1\" width=\"500\"></img> |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSSZRWtAs6Dg",
        "colab_type": "text"
      },
      "source": [
        "# Back Propogation Through Time (BPTT)\n",
        "\n",
        "Lets look at the timestep t=3, the error associated w.r.t Wx depends on : vector S3 and its predecessor S2 and S1.<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/BPTT.png?raw=1\" width=\"600\"></img><br>\n",
        "\n",
        "Looking at the pattern above while calculating the *accumulative gradient*, we can generalize the formula for Back Propogation Through Time (BPTT)as follows - <br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/General%20formula%20for%20BPTT.png?raw=1\" width=\"300\"></img><br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UziWjf9s6AH",
        "colab_type": "text"
      },
      "source": [
        "# Drawbacks of RNNs\n",
        "\n",
        "## Vanishing Gradient Problem\n",
        "\n",
        "In RNNs, if we continue to back-propogate further after 8-9 time steps, the contributions of information (graident) keeps on decreading geometrically over time which is known as the *vanishing gradient problem.* Here is where the **LSTM** comes into picture.<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/LSTM%20Intro.png?raw=1\" width=\"600\"></img>\n",
        "\n",
        "## Exploding Gradient Problem\n",
        "\n",
        "In RNNs we can also have the opposite problem, called the *exploding gradient* problem, in which the value of the gradient grows uncontrollably. A simple solution for the exploding gradient problem is **Gradient Clipping.**\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Gradient%20Clipping.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN9iaHdXs59m",
        "colab_type": "text"
      },
      "source": [
        "# Long Short Term Memory Cells (LSTM Cells)\n",
        "\n",
        "## Basics of LSTM\n",
        "\n",
        "Basic RNN was unable to retain long term memory to make prediction regarding the current picture is that od a wolf or dog. This is where LSTM comes into picture. The LSTM cell allows a recurrent system to learn over many time steps without the fear of losing information due to the vanishing gradient problem. It is fully differentiable, therefore gives us the option of easily using backpropagation when updating the weights. Below is the a sample mathematical model of an LSTM cell - <br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/01.lstm_cell.png?raw=1\"></img><br>\n",
        "\n",
        "\n",
        "In an LSTM, we would expect the following behaviour -\n",
        "\n",
        "\n",
        "| Expected Behaviour of LSTM                                                                   | Reference Diagram                                                       |\n",
        "|----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
        "| 1. Long Term Memory (LTM) and Short Term Memory (STM) to combine and produce correct output. | <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/05.%20lstm_basics_1.png?raw=1\" width=\"300px\" height=\"230px\"> |\n",
        "| 2. LTM and STM and event should update the new LTM.                                          | </img>  <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/06.%20lstm_basics_2.png?raw=1\" width=\"530px\" height=\"250px\"></img>  |\n",
        "| 3. LTM and STM and event should update the new STM.                                          | <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/07.%20lstm_basics_3.png?raw=1\" width=\"530px\" height=\"250px\"></img>          |\n",
        "\n",
        "\n",
        "\n",
        "## How LSTMs work?\n",
        "\n",
        "| LSTM consists of 4 types of gates -  <br>1. Forget Gate<br>  2. Learn Gate<br> 3. Remember Gate<br> 4. Use Gate<br> | <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/10.%20lstm_architecture_02.png?raw=1\" width=\"530px\" height=\"250px\"></img> |\n",
        "|-------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------|\n",
        "\n",
        "### LSTM Explained\n",
        "Assume the following - \n",
        "1. LTM = Elephant\n",
        "2. STM = Fish\n",
        "3. Event = Wolf/Dog\n",
        "\n",
        "| LSTM Operations                                                                                                                                                                                            | Reference Video                                      |\n",
        "|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------|\n",
        "| **LSTM places LTM, STM and Event as follows -**<br> 1. Forget Gate = LTM<br>  2. Learn Gate = STM + Event<br> 3. Remember Gate = LTM + STM + Event<br> 4. Use Gate = LTM + STM + Event<br> 5. In the end, LTM and STM are updated.<br> | <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Animated%20GIF-downsized_large.gif?raw=1\"></img> |\n",
        "\n",
        "\n",
        "## General Architecture of LSTM \n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/LSTM%20Architecture.png?raw=1\" width=\"600\"><img>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Learn Gate\n",
        "Learn gate takes into account **short-term memory and event** and then ignores a part of it and retains only a part of information.<br>\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/11.%20learn_gate.png?raw=1\" height=\"200px\" width=\"500px\"></img>\n",
        "\n",
        "### Mathematically Explained\n",
        "STM and Event are combined together through **activation function** (tanh), which we further multiply it by a **ignore factor** as follows -<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/12.lean_gate_equation.png?raw=1\" height=\"200px\" width=\"500px\"></img>\n",
        "\n",
        "## Forget Gate\n",
        "Forget gate takes into account the LTM and decides which part of it to keep and which part of LTM is useless and forgets it. LTM gets multiplied by a **forget factor** inroder to forget useless parts of LTM. <br>\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/13.%20forget_gate.png?raw=1\" height=\"200px\" width=\"500px\"></img>\n",
        "\n",
        "## Remember Gate\n",
        "Remember gate takes LTM coming from Forget gate and STM coming from Learn gate and combines them together. Mathematically, remember gate adds LTM and STM.<br><br>\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/14.%20remember_gate.png?raw=1\" height=\"200px\" width=\"400px\"></img> <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/15.%20remember_gate_equation.png?raw=1\" height=\"200px\" width=\"450px\"></img>\n",
        "\n",
        "## Use Gate\n",
        "Use gate takes what is useful from LTM and what's useful from STM and generates a new LTM.<br><br>\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/16.%20use_gate.png?raw=1\" height=\"200px\" width=\"400px\"></img> <img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/17.%20use_gate_equation.png?raw=1\" height=\"200px\" width=\"450px\"></img>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij4TC1Ots57C",
        "colab_type": "text"
      },
      "source": [
        "# RNNs and LSTM for Text Generation\n",
        "\n",
        "\n",
        "## Drawbacks of one-hot encoding \n",
        "\n",
        "Considering an example of an excert from a book containing large collection of dataset and when you use these words as an input to RNN, we can one-hot encode them, but this would mean that we will end up having giant vector with mostly zeros except that one entry as shown below:<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/One%20hot%20encoded%20vectors.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "Then we pass this one-hot encoded vector into hidden-layer of RNN and the result is a huge matrix of values most of which are zeros because of the initial one-hot encoding and this is really *computaionally inefficient*.<br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Computationally%20in-efficient.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "This is where *Embeddings* come into picture.\n",
        "\n",
        "\n",
        "## Word Embeddings\n",
        "\n",
        "Word embeddings is a general technique of reducing the dimensionality of text data, but the embedding models can also learn some interesting traits about words in a vocabulary.<br>\n",
        "\n",
        "Embeddings can improve the ability of neural networks to learn from text data by representing them as *lower dimensional vectors.*\n",
        "\n",
        "The idea here is when we multiply one-hot encoded vector with weight-matrix, returns only the row of the matrix that corresponds to the 1 or the on input unit.<br><br>\n",
        "\n",
        "Hence, instead of doing matrix multiplication, we use weight-matrix as a look-up table and instead of representing words as one-hot vectors, we encode each word with a unique integer.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Embedding%20Lookup.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9xZzBvon7A2",
        "colab_type": "text"
      },
      "source": [
        "# Look-up Tables\n",
        "\n",
        "Considering the example of \"heart\" mentioned above, we see that \"heart\" is encoded as the integer \"958\", we can look-up the embedding vector for this word in the 958th row of the embedding weight matrix. This is called a *look-up table*\n",
        "\n",
        "## Dimensions of Look-up table\n",
        "\n",
        "If we have a vocabulary of 10k words, then we will have a 10k row embedded weight matrix. The width of the table is called *embedding dimensions*.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/embedding_lookup_table.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-jTnfugp8QO",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec Models\n",
        "\n",
        "Word2Vec model provides much efficient representations by finding vectors that represents words.<br>\n",
        "\n",
        "There are 2 architectures for implementing Word2Vec -\n",
        "1. CBOW (Continous Bag Of Words)\n",
        "2. Skip-gram\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/word2vec_architectures.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "\n",
        "We have implemened *Talking Points* using the *Skip-gram* model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6l01P26nJMr",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "\n",
        "## Description:\n",
        "\n",
        "We have gathered the data for training our model from Kaggle's dataset [US Financial News Articles](https://www.kaggle.com/jeet2016/us-financial-news-articles?)\n",
        "\n",
        "\n",
        "### Context\n",
        "\n",
        "The data set is rich with metadata, containing the source of the article, the time it was published to the author details and Images related to every article. \n",
        "Excellent for text analysis and combined with any other related entity dataset, it could give some astounding results.\n",
        "\n",
        "### Content\n",
        "\n",
        "The main Zip file contains 5 other folders , each for every month in 2018 from January to May.\n",
        "\n",
        "JSON files have articles based on the following criteria:\n",
        "\n",
        "News publishers: Bloomberg.com, CNBC.com, reuters.com, wsj.com, fortune.com\n",
        "Language: Only English\n",
        "Country: United States\n",
        "News Category: Financial news only\n",
        "\n",
        "The source for the articles (Archive source: httsps://Webhose.io/archive )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMheWJ1hJyrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO :: Add !wget commandfile\n",
        "\n",
        "'https://drive.google.com/file/d/1CJwas1hzNf9cY6_kZ4WnG2BhoOFxQsAc/view?usp=sharing'\n",
        "#os.chdir('49948-90823-bundle-archive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHagKMC9lj10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dIgYMfelsXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42aKA48o6KFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "print(os.chdir('2018_01_112b52537b67659ad3609a234388c50a'))\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMVVBBnmlz6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76OCf7eLl41_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download = drive.CreateFile({'id': '1CJwas1hzNf9cY6_kZ4WnG2BhoOFxQsAc'})\n",
        "download.GetContentFile('stock_news.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNWgZl9vmJLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip 'stock_news.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnKlMnNUm3nC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "0fcc85a6-eb8a-4c6b-e213-d81c60b38822"
      },
      "source": [
        "\n",
        "os.chdir('./49948-90823-bundle-archive/2018_04_112b52537b67659ad3609a234388c50a')\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/49948-90823-bundle-archive/2018_04_112b52537b67659ad3609a234388c50a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrIb1XiVssGc",
        "colab_type": "text"
      },
      "source": [
        "## Combining Stock News\n",
        "\n",
        "Here, we append the stock news from our dataset into one common txt file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwyRqQuh6PD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import glob\n",
        "import pprint\n",
        "keywordList = []\n",
        "news_feed = []\n",
        "print(os.getcwd())\n",
        "path = os.getcwd()\n",
        "for filename in glob.glob(os.path.join(path, '*.json')): #only process .JSON files in folder. \n",
        "    print(filename)     \n",
        "    with open(filename) as currentFile:\n",
        "        data=currentFile.read().replace('\\n', '')\n",
        "        json_data = json.loads(data)\n",
        "        title =json_data[\"title\"]\n",
        "        news = json_data[\"text\"]\n",
        "        news_feed.append(title)\n",
        "        news_feed.append(news)\n",
        "\n",
        "# with open('Untitled document.txt', 'r') as f:\n",
        "#   data = f.readlines()\n",
        "#   news_feed.append(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wKWpvCg6wNt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "971aab5d-42a3-4f30-ebaa-10bf4da23e20"
      },
      "source": [
        "print(len(news_feed))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At-tEFKN-xtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5e368a0b-0b5f-449d-883a-2a17bae2a874"
      },
      "source": [
        "print(news_feed[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['At war with Alibaba: Top brands fight China e-commerce giant', 'It was looking like a banner year for business in China . The U.S. clothing company was expecting a 20 percent jump in online sales on Alibaba\\'s Tmall, thanks to the e-commerce giant\\'s massive reach.\\nBut executives soon learned that what Alibaba gives, it can also take away.\\nThe company refused to sign an exclusive contract with Alibaba, and instead participated in a big sale promotion with its archrival, JD.com . Tmall punished them by taking steps to cut traffic to their storefront, two executives told The Associated Press.\\nThey said advertising banners vanished from prominent spots in Tmall sales showrooms, the company was blocked from special sales and products stopped appearing in top search results.\\nThe well-known American brand saw its Tmall sales plummet 10 to 20 percent for the year.\\n\"Based on our sales record, we should have been in a prominent position, but we were at the bottom of the page,\" said the brand\\'s e-commerce director, who spoke only on condition of anonymity for fear of further retaliation. \"That\\'s a clear manipulation of traffic. That\\'s a clear punishment.\"\\nAs the Trump administration pushes China to play by fair trade rules, companies are caught in a quieter but no less crucial struggle for rules-based access to a $610 billion online marketplace, an AP investigation has found.\\nExecutives from five major consumer brands told the AP that after they refused to enter exclusive partnerships with Alibaba, traffic to their Tmall storefronts fell, hurting sales. Three are American companies with billions in annual sales that rely on China for growth.\\nAlibaba Group Holding denied punishing the companies.\\nIn a statement, Alibaba said pursuing exclusive deals is a common industry practice and called the charges of coercion \"completely false.\"\\n\"Alibaba and Tmall conduct business in full compliance with Chinese laws,\" Alibaba said. \"Like many e-commerce platforms, we have exclusive partnerships with some of the merchants on Tmall. The merchant decides to choose such an arrangement because of the attractive services and value Tmall brings to them.\"\\nThe executives spoke to the AP only on condition of anonymity for fear of reprisals, but their concerns were echoed by a U.S. industry group, brand consultants and policy makers in China and JD.com itself.\\nIn a speech about cyberspace last week, Chinese president Xi Jinping said ensuring free and fair competition online was a regulatory priority, citing the need \"to cultivate a fair market environment, strengthen intellectual property protection, and oppose monopoly and unfair competition,\" state media reported.\\nIn its months-long investigation, the AP interviewed more than 30 people and reviewed two contracts from Alibaba that contained the previously unreported exclusivity clauses. The AP found that the platforms that control access to Chinese consumers online wield such enormous power that even multi-billion dollar foreign companies can have trouble fighting back.\\n\"We urge the authorities to quickly investigate and take steps to ensure such practices are eliminated from the growing Chinese marketplace,\" said Stephen Lamar, executive vice-president of the American Apparel & Footwear Association, adding that members of his industry group had complained about unfair competitive practices by Alibaba.\\nJD.com is a member and sponsor of the trade group.\\nImagine a company twice as profitable as Amazon that each year serves more people than live in all of North America. That\\'s Alibaba. It claims to be the marketplace for nearly $550 billion a year in sales — more than is sold online in the entire U.S. economy.\\nThe trials of the affected companies offer a rare window onto a bruising business culture forged in China that could spread as Alibaba takes its aggressive, innovative and hugely profitable model of e-commerce global. To the extent that their products are manufactured in the United States — and some are — constricting sales in China\\'s critical growth market can also deepen the imbalance of trade between China and the U.S., a gap that is a top concern for the Trump administration.\\nThe competition between Alibaba and JD.com is so infamous in China — and so dirty — it\\'s been dubbed the \"great cat-and-dog war,\" after Tmall\\'s black-cat mascot and JD.com\\'s white dog.\\nWang Hongbo, a consultant who helps Chinese brands sell online abroad, echoed the problems cited by the companies who spoke to AP.\\n\"Many brands complained about this to us. Because they didn\\'t fall in line, they faced restrictions on Tmall,\" he said.\\nJD.com said that over 100 Chinese brands defected last year due to pressure from its main rival, an assertion Alibaba and some brands have contested. The exodus appears to have had a lasting impact.\\n\"Based on the feedbacks we received from these merchants, the move was mainly due to the coercive tactics from our competition, which if proven true would be illegal and clearly against the merchants\\' will,\" said Sidney Huang, JD.com\\'s chief financial officer, said in a November earnings call.\\nPeacebird, a Chinese fashion company, is among those that left JD.com last year. But Weng Jianghong, the company\\'s general manager of e-commerce, said Alibaba had not coerced them and the decision to focus on Tmall was strategic.\\n\"We will centralize and develop the limited resources of our company on Tmall,\" he said.\\nMany companies, including JD.com, do exclusive deals. However, JD.com maintains that it doesn\\'t strategically push merchants for exclusivity.\\n\"We support fair and open competition because greater choice is always better for brands and users,\" JD.com said in a statement. \"We are winning over customers by providing a superior shopping experience, rather than by limiting the options of brands or consumers.\"\\nJD.com is still trying to get brands to return. \"We do believe there will be more merchants coming back,\" Huang said in a call last month with analysts. \"But I do not expect a very quick fix.\"\\nPlay or pay\\nTmall controlled six of every ten dollars spent overall for business-to-consumer sales online in China in the second half of last year — and even more for sectors like apparel — giving it enormous power over companies that rely on Alibaba for access to Chinese consumers online.\\nThe contracts reviewed by AP offered a suite of benefits in exchange for exclusivity. One contract specified that brands must not operate storefronts on other e-commerce platforms without Tmall\\'s written permission. The other contract mandated that new products not be launched on competing platforms and barred brands from sales promotions on other platforms without Tmall\\'s written permission.\\nSuch sales events are the lifeblood of online commerce in China. The country\\'s massive Singles Day promotion in November, which started as an anti-Valentine\\'s Day gimmick, is now the world\\'s largest e-commerce event. Last year, Alibaba said $25 billion worth of merchandise was sold on its platforms alone, compared with just $14.5 billion in total online sales in the U.S. for Thanksgiving Day, Black Friday and Cyber Monday combined, according to data from Adobe Systems .\\nBrands cited commercial, ideological and legal reasons for refusing to cut off business with JD.com.\\nSome said that different people shop in different ways on JD.com and Tmall, so cutting off JD.com means cutting off access to a pool of potential shoppers.\\n\"It\\'s clear from the data we look at these are distinct consumer pools,\" said the China head of a publicly-traded company. \"If I lost the JD business I would lose a certain part of that business. Another part is on principle: This is blatant anticompetitive behavior.\"\\nOthers cited legal concerns. \"We didn\\'t want to go for it in part because we thought it might be an illegal agreement in restraint of trade,\" said an executive for a second publicly-traded company.\\n\"We\\'re chided when we participate in promotional events on other platforms,\" he added. \"What\\'s never said but actually happens when we don\\'t cooperate in the way they want us to is our traffic falls. It\\'s not a coincidence.\"\\nTwo companies said they granted concessions to Alibaba, agreeing to exclusive product launches, raising their prices on JD.com, or removing ads promoting JD.com sales. Traffic to their Tmall shops rebounded. One company said it ultimately closed its flagship on JD.com to salvage Tmall sales.\\n\"You have to go beg,\" said the China director of a multi-billion dollar publicly-traded company.\\nThe great cat-and-dog war Tmall and JD.com have different business models but they are increasingly pushing onto each other\\'s turf.\\nAlibaba\\'s online marketplaces connect buyers and sellers. Alibaba earns money from advertising, as well as commissions and fees. JD.com runs a similar marketplace but, like Amazon, also buys products from brands, then sells and distributes the merchandise itself.\\nAlibaba has taken aim at JD.com\\'s long-standing dominance in electronics, while JD.com hopes to cut into Tmall\\'s core apparel category. Both have expanded into groceries and poured hundreds of millions of dollars into acquisitions to extend their reach into brick-and-mortar businesses.\\nThe result is an escalating turf fight that carries a chilling message for brands: Either you\\'re with us or against us. The Chinese have a name for this unwritten rule, \"er xuan yi,\" choose one of two.\\n\"\\'Choose one of two\\' is a tacit understanding that has been reached by everyone, but you do not say it directly,\" said Zhuo Saijun, who until 2015 was a general manager of e-commerce research at Analysys, a Beijing-based big data consultancy. \"This is certainly a problem for the development of retail sales channels. It is a business ethics problem, and this is how monopolies develop.\"\\nSome policymakers have raised concerns about monopolistic tendencies in Chinese e-commerce and called for more effective regulation and enforcement.\\n\"Unfair competition still exists,\" Wang Bingnan, a deputy director at China\\'s Ministry of Commerce, said in a June speech about China\\'s e-commerce market. \"Behaviors like forced `choose one of two,\"\\' he added, \"are hard for regulators to define, prove or deal with accurately.\"\\nIt\\'s not clear whether Alibaba\\'s actions would be illegal, nor is it certain that the evidence of coercion that brands have managed to collect would hold up in court.\\nUnder China\\'s anti-monopoly laws, companies that dominate a market cannot demand exclusivity without justification. A 2015 regulation also specifically bars e-commerce platforms from restricting brands\\' participation in promotions on other platforms.\\nThe rules are designed to prevent dominant players from squeezing out the competition, which could ultimately hurt both brands and consumers by giving a single, monopolistic player absolute control over prices.\\nJD.com has complained about anticompetitive tactics before. In 2015, the company filed a complaint with the State Administration for Industry and Commerce, a corporate regulator, accusing Alibaba of pressuring brands into doing exclusive Singles Day sales promotions -- a charge Alibaba denied. The complaint was kicked to a regional office in Zhejiang province, where Alibaba has its headquarters.\\nNothing more was ever heard about it.\\nThe regulators did not respond to requests for comment.\\nAlibaba said that while JD.com focuses \"on groundless complaints to explain why they are losing brands, we at Alibaba are squarely focused on making our platform the best for our merchants.\"\\nMr Ma goes global The battles now being waged within China\\'s e-commerce sector could well impact the culture and norms of e-commerce globally — at least if Alibaba\\'s chairman, Jack Ma , has his way.\\nAlibaba aims to serve 2 billion consumers by 2036 — or about one in four people now on the planet. Already, the value of goods sold on Alibaba\\'s platforms in fiscal year 2017 was $547 billion, larger than the gross domestic product of Sweden .\\nIn June, Ma told investors that his company will rank as the fifth largest economy in the world. \"Just say USA, China, Europe , maybe Japan and us,\" Ma said.\\nThe company has been aggressively recruiting foreign brands to sell on its platforms, and they have come, in droves. Alibaba said it signed up 60,000 international brands for its massive Single\\'s Day sale in November, up from 5,000 in 2015.\\nAlibaba\\'s retail sales outside of China also are growing fast — they more than doubled last fiscal year to 7.3 billion yuan ($1.1 billion), or 5 percent of total revenue.\\nAmerica remains at the heart of Ma\\'s ambition. He told president-elect Donald Trump in Jan. 2017 that he would create a million U.S. jobs by facilitating trade between businesses in the U.S and consumers in China — a pledge he now says is imperiled by the brewing trade war between the two countries.\\nBrands now caught in the great cat and dog war have adopted different strategies to avoid becoming collateral damage.\\nAn e-commerce manager at a major European brand said she\\'d be happy to offer totally different products on Tmall and JD.com to stay out of trouble, but worries her bosses won\\'t go for it because it cuts off potential buyers.\\nSometimes, she said, it feels \"like we\\'re working for those platforms.\"', \"De La Rue will not appeal loss of UK 'Brexit' passport contract\", \"April 18, 2018 / 6:23 AM / Updated 4 hours ago De La Rue profit hit as drops blue British passport bid Paul Sandle 3 Min Read \\nLONDON (Reuters) - De La Rue ( DLAR.L ) abandoned its challenge to Britain’s decision to award the contract for new blue post-Brexit passports to a foreign firm and issued a profit warning on Wednesday. A handout photograph shows the original 'blue' British passport, which was subsequently replaced by the burgundy EU British passport, supplied by the UK government in London, Britain, March 22, 2018. UK Government/Handout via Reuters \\nIts shares fell 9 percent to a year low of 446 pence in early trading and were down 4 percent at 0851 GMT after De La Rue said it would write-off about 4 million pounds of costs associated with the failed bid. \\nTogether with delays in some contracts in the last week of its financial year, this would result in it missing profit expectations, De La Rue said in a statement. \\nPrime Minister Theresa May said the decision to change British passports from the burgundy shade used by most European Union countries to the traditional dark blue was an expression of British independence and sovereignty. \\nBut reports that Franco-Dutch firm Gemalto ( GTO.AS ) had won the tender to produce the new passport was criticised by some politicians and newspapers as unpatriotic, and De La Rue had said it would challenge the decision. Slideshow (2 Images) \\nDe La Rue, which prints 7 billion banknotes and 15 million passports a year, said that having considered all options it would not appeal the decision, which the British government said followed a “rigorous, fair and open competition”. SURPRISED AND DISAPPOINTED \\nThe existing contract to make British passports is worth 400 million pounds and the new contract starts in October 2019, after Britain leaves the EU in March that year. \\nDe La Rue’s Chief Executive Martin Sutherland told BBC radio that he remained “surprised and disappointed”, but he had taken a pragmatic business decision not to appeal. \\nUnderlying operating profit for the year to end-March would be in the low to mid 60s million pound range, it said. \\nAnalysts at Investec, who were predicting 71 million pounds, said it was a “disappointing outcome”. \\nRevenue for the year had increased by about 6 percent, with growth across all product lines, it said, although it added that it was “cautious” about its current financial year. \\nIt said it would assist with the transition to the new supplier, and was expecting no impact on its performance in the next 18 months. \\nTrade union Unite said news that De La Rue was abandoning its appeal would come as a bitter blow to workers in Gateshead, north east England, who now faced an uncertain future. \\n“Workers will feel let down that the company is not prepared to fight the government’s decision to ship the production of the new blue passport overseas,” Unite national officer Louisa Bull said. Editing by Kate Holton/Guy Faulconbridge/Alexander Smith\", 'Trumps greet the Macrons for White House state dinner', 'Trumps greet the Macrons for White House state dinner Wednesday, April 25, 2018 - 01:27\\nFrench President Emmanuel Macron and his wife Brigitte are greeted by U.S. President Donald Trump and first lady Melania for the White House state dinner. Rough Cut (no reporter narration).\\nFrench President Emmanuel Macron and his wife Brigitte are greeted by U.S. President Donald Trump and first lady Melania for the White House state dinner. Rough Cut (no reporter narration). //reut.rs/2Ka52Gq', 'ESCO Corporation to Join Leading Global Engineering Company, Weir', \"PORTLAND, Ore., April 19, 2018 (GLOBE NEWSWIRE) -- ESCO Corporation (“ESCO”), the Portland-based, recognized global leader in ground engaging tools for mining and construction markets, has entered into an agreement to be acquired by The Weir Group PLC (“Weir”), one of the world’s leading engineering businesses, for an enterprise value of $1.285 billion.\\nThe combined businesses will provide a unique offering to global mining customers with a range of premium, market-leading brands focused on increasing customer productivity and reducing total cost of ownership. ESCO’s leadership in ground engaging tools complements Weir’s portfolio of leading products and services that are used on mine sites to process materials extracted by ESCO’s equipment.\\nFounded in 1871 in Glasgow, Scotland, Weir is a leader in mining and upstream oil and gas with facilities in more than 70 countries and approximately 15,000 employees. The Group is publicly traded and has been a member of the London Stock Exchange since 1946.\\n“The foundation of our business for more than 100 years has been delivering value-added solutions to customers through a proud tradition of quality and customer-driven innovation,” said ESCO Chairman and CEO, Cal Collins. “This merger is exciting for ESCO. It combines two premium brands and positions us to better serve customers around the world. The merger of ESCO into Weir is a great fit, both culturally and strategically.”\\nCompletion of the acquisition is expected to take place in the third quarter of 2018 following customary regulatory clearances. ESCO will operate as a standalone business as part of Weir for the duration of 2018, with integration starting in 2019. No significant change to ESCO employee numbers or facilities are expected as a result of this combination. ESCO’s Portland headquarters will continue to serve as a global center of excellence for ESCO products.\\n“With ESCO we’ll be joined by a world-class team and add another leading global brand. Together, Weir Minerals and ESCO will create a unique customer proposition as the premium provider of mission critical surface mining solutions from extraction to concentration, built on proprietary technology, superior wear life and supported by an unrivalled service network,” said Weir CEO, Jon Stanton.\\nThe combined business will employ approximately 18,000 people with operations in over 70 countries. ESCO products will continue to be marketed and sold under the ESCO brand.\\nWells Fargo Securities acted as ESCO's exclusive financial adviser for the transaction. Stoel Rives LLP served as legal counsel and Linklaters LLP as UK merger counsel and competition law counsel to ESCO.\\nAbout ESCO ® Corporation\\nESCO Corporation engineers, manufactures and services mission critical equipment used by companies in mining, construction, and industrial markets. With more than 100 years of experience in the science of metals, alloys and wear materials, ESCO products are used in a wide range of applications, including highly abrasive digging, recycling, excavation, snow plowing and many more. ESCO is recognized as an industry leader delivering innovative products and custom engineered solutions that enhance customer productivity and safety. Privately held, ESCO is headquartered in Portland, Ore., and maintains a global network of more than 70 manufacturing plants, supply & service facilities and offices in 20 countries. For more information, visit escocorp.com .\\nGlobal Media Contact: Hayley Shauklas | (503) 778-6764 | hayley.shauklas@escocorp.com\\nSource:ESCO Corporation\", 'Kinsale Capital Group Announces First Quarter Earnings Release Date and Conference Call', 'RICHMOND, Va., April 11, 2018 (GLOBE NEWSWIRE) -- Kinsale Capital Group, Inc. (NASDAQ:KNSL) announced today that it will release financial results for the first quarter of 2018 after the market closes on Thursday, May 3, 2018.\\nThe Company will host a conference call to discuss its results with analysts and investors on Friday, May 4, 2018, beginning at 9:00 a.m. (Eastern Time). The release will also be available on the Company’s website, www.kinsalecapitalgroup.com .\\nTo access the conference call, dial (844) 239-5282, conference ID# 4778106, or via the Internet by going to www.kinsalecapitalgroup.com and clicking on the “Investor Relations” link. Please visit the website at least 15 minutes before the call to register and download and install any necessary audio software. A replay of the call will be available on the website until the close of business on July 3, 2018.\\nAbout Kinsale Capital Group\\nKinsale Capital Group, Inc. is a specialty insurance group headquartered in Richmond, Virginia, focusing on the excess and surplus lines market.\\nFor more information contact:\\nKinsale Capital Group, Inc.\\n(804) 289-1272\\nir@kinsalecapitalgroup.com\\nSource:Kinsale Capital Group, Inc.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNbaA6Zqn15O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f = open('stock_twitter_news.txt', 'w')\n",
        "f.write('.'.join(news_feed))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_knGoc4fs-yq",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing Stock News \n",
        "\n",
        "The following section pre-processes our text file so that -\n",
        "1. Any punctuation are converted into tokens, so a period is changed to a bracketed period.\n",
        "2. In this data set, there aren't any periods, but it will help in other NLP problems.\n",
        "3. It removes all words that show up five or fewer times in the dataset.This will greatly reduce issues due to noise in the data and improve the quality of the vector representations.\n",
        "4. It returns a list of words in the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti_7RYkK-4KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "\n",
        "SPECIAL_WORDS = {'PADDING': '<PAD>'}\n",
        "\n",
        "\n",
        "def load_data(path):\n",
        "    \"\"\"\n",
        "    Load Dataset from File\n",
        "    \"\"\"\n",
        "    input_file = os.path.join(path)\n",
        "    with open(input_file, \"r\") as f:\n",
        "        data = f.read()\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n",
        "    \"\"\"\n",
        "    Preprocess Text Data\n",
        "    \"\"\"\n",
        "    text = load_data(dataset_path)\n",
        "    \n",
        "    # Ignore notice, since we don't use it for analysing the data\n",
        "    text = text[81:]\n",
        "\n",
        "    token_dict = token_lookup()\n",
        "    for key, token in token_dict.items():\n",
        "        text = text.replace(key, ' {} '.format(token))\n",
        "\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "\n",
        "    vocab_to_int, int_to_vocab = create_lookup_tables(text + list(SPECIAL_WORDS.values()))\n",
        "    int_text = [vocab_to_int[word] for word in text]\n",
        "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n",
        "\n",
        "\n",
        "def load_preprocess():\n",
        "    \"\"\"\n",
        "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
        "    \"\"\"\n",
        "    return pickle.load(open('preprocess.p', mode='rb'))\n",
        "\n",
        "\n",
        "def save_model(filename, decoder):\n",
        "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
        "    torch.save(decoder, save_filename)\n",
        "\n",
        "\n",
        "def load_model(filename):\n",
        "    save_filename = os.path.splitext(os.path.basename(filename))[0] + '.pt'\n",
        "    return torch.load(save_filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U4CntYOzQC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "# load in data\n",
        "\n",
        "data_dir = 'stock_twitter_news.txt'\n",
        "text = load_data(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtCkjEqRvEPA",
        "colab_type": "text"
      },
      "source": [
        "# Statistics of our dataset\n",
        "\n",
        "Here we are printing some statistics of our dataset such as number of unique words, number of lines and average number of words in each line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLpK9exu1Enq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "533a4e12-4649-48b1-c882-ed384b5ee5b2"
      },
      "source": [
        "view_line_range = (0, 10)\n",
        "\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "print('Dataset Stats')\n",
        "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
        "\n",
        "lines = text.split('\\n')\n",
        "print('Number of lines: {}'.format(len(lines)))\n",
        "word_count_line = [len(line.split()) for line in lines]\n",
        "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
        "\n",
        "print()\n",
        "print('The lines {} to {}:'.format(*view_line_range))\n",
        "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Stats\n",
            "Roughly the number of unique words: 785718\n",
            "Number of lines: 900003\n",
            "Average number of words in each line: 26.306250090277477\n",
            "\n",
            "The lines 0 to 10:\n",
            "At war with Alibaba: Top brands fight China e-commerce giant.It was looking like a banner year for business in China . The U.S. clothing company was expecting a 20 percent jump in online sales on Alibaba's Tmall, thanks to the e-commerce giant's massive reach.\n",
            "But executives soon learned that what Alibaba gives, it can also take away.\n",
            "The company refused to sign an exclusive contract with Alibaba, and instead participated in a big sale promotion with its archrival, JD.com . Tmall punished them by taking steps to cut traffic to their storefront, two executives told The Associated Press.\n",
            "They said advertising banners vanished from prominent spots in Tmall sales showrooms, the company was blocked from special sales and products stopped appearing in top search results.\n",
            "The well-known American brand saw its Tmall sales plummet 10 to 20 percent for the year.\n",
            "\"Based on our sales record, we should have been in a prominent position, but we were at the bottom of the page,\" said the brand's e-commerce director, who spoke only on condition of anonymity for fear of further retaliation. \"That's a clear manipulation of traffic. That's a clear punishment.\"\n",
            "As the Trump administration pushes China to play by fair trade rules, companies are caught in a quieter but no less crucial struggle for rules-based access to a $610 billion online marketplace, an AP investigation has found.\n",
            "Executives from five major consumer brands told the AP that after they refused to enter exclusive partnerships with Alibaba, traffic to their Tmall storefronts fell, hurting sales. Three are American companies with billions in annual sales that rely on China for growth.\n",
            "Alibaba Group Holding denied punishing the companies.\n",
            "In a statement, Alibaba said pursuing exclusive deals is a common industry practice and called the charges of coercion \"completely false.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCi3F6wEvTda",
        "colab_type": "text"
      },
      "source": [
        "# Vocab2int & Int2vocab\n",
        "\n",
        "Here we are creating 2 dictionaries to convert words to integers (`vocab_to_int`) and integers to vocab (`int_to_vocab`). The integers are assigned in descending order of the frequency, so the most frequent word, \"the\",  is given the integer \"0\" and the next most frequent word is given \"1\" and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trZWjzph1Mn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def create_lookup_tables(text):\n",
        "    \"\"\"\n",
        "    Create lookup tables for vocabulary\n",
        "    :param text: The text of tv scripts split into words\n",
        "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    word_count = Counter(text)\n",
        "    sorted_vocab = sorted(word_count, key = word_count.get, reverse=True)\n",
        "    int_to_vocab = {ii:word for ii, word in enumerate(sorted_vocab)}\n",
        "    vocab_to_int = {word:ii for ii, word in int_to_vocab.items()}\n",
        "    \n",
        "    # return tuple\n",
        "    return (vocab_to_int, int_to_vocab)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvE9O0F31Sa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def token_lookup():\n",
        "    \"\"\"\n",
        "    Generate a dict to turn punctuation into a token.\n",
        "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
        "    \"\"\"\n",
        "    # TODO: Implement Function\n",
        "    token = dict()\n",
        "    token['.'] = '<PERIOD>'\n",
        "    token[','] = '<COMMA>'\n",
        "    token['\"'] = 'QUOTATION_MARK'\n",
        "    token[';'] = 'SEMICOLON'\n",
        "    token['!'] = 'EXCLAIMATION_MARK'\n",
        "    token['?'] = 'QUESTION_MARK'\n",
        "    token['('] = 'LEFT_PAREN'\n",
        "    token[')'] = 'RIGHT_PAREN'\n",
        "    token['-'] = 'QUESTION_MARK'\n",
        "    token['\\n'] = 'NEW_LINE'\n",
        "    return token\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_sNwT901WUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "# pre-process training data\n",
        "preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lCVmtHB1Y8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "import helper\n",
        "\n",
        "int_text, vocab_to_int, int_to_vocab, token_dict = load_preprocess()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T1ovulP1bQZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93d5226f-ff4b-41cc-a554-cc4ac0c99cbc"
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "# Check for a GPU\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "if not train_on_gpu:\n",
        "    print('No GPU found. Please use a GPU to train your neural network.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No GPU found. Please use a GPU to train your neural network.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLqlircpw-Ic",
        "colab_type": "text"
      },
      "source": [
        "# Batching Data\n",
        "\n",
        " We'll use `TensorDataset` to provide a known format to our dataset; in combination with DataLoader, it will handle batching, shuffling, and other dataset iteration functions.<br>\n",
        "We can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.\n",
        "\n",
        "```python\n",
        "data = TensorDataset(feature_tensors, target_tensors)\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "```\n",
        "\n",
        "For example, say we have these as input:<br>\n",
        "```\n",
        "words = [1, 2, 3, 4, 5, 6, 7]\n",
        "sequence_length = 4\n",
        "```\n",
        "Our first feature_tensor should contain the values:<br>\n",
        "```\n",
        "[1, 2, 3, 4]\n",
        "```\n",
        "And the corresponding target_tensor should just be the next \"word\"/tokenized word value:<br>\n",
        "```\n",
        "5\n",
        "```\n",
        "This should continue with the second feature_tensor, target_tensor being:<br>\n",
        "```\n",
        "[2, 3, 4, 5]  # features\n",
        "6             # target\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LwWUJmz1gya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def batch_data(words, sequence_length, batch_size):\n",
        "    \"\"\"\n",
        "    Batch the neural network data using DataLoader\n",
        "    :param words: The word ids of the TV scripts\n",
        "    :param sequence_length: The sequence length of each batch\n",
        "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
        "    :return: DataLoader with batched data\n",
        "    \"\"\"\n",
        "    # TODO: Implement function\n",
        "    n_batches = len(words)//batch_size\n",
        "    x, y = [], []\n",
        "    words = words[:n_batches*batch_size]\n",
        "    \n",
        "    for ii in range(0, len(words)-sequence_length):\n",
        "        i_end = ii+sequence_length        \n",
        "        batch_x = words[ii:ii+sequence_length]\n",
        "        x.append(batch_x)\n",
        "        batch_y = words[i_end]\n",
        "        y.append(batch_y)\n",
        "    \n",
        "    data = TensorDataset(torch.from_numpy(np.asarray(x)), torch.from_numpy(np.asarray(y)))\n",
        "    data_loader = DataLoader(data, shuffle=True, batch_size=batch_size)\n",
        "        \n",
        "    \n",
        "    # return a dataloader\n",
        "    return data_loader\n",
        "\n",
        "# there is no test for this function, but you are encouraged to create\n",
        "# print statements and tests of your own\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-nSbEYC1yBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "9bf83d98-d43a-4d28-f3ab-ac87d3ed9f23"
      },
      "source": [
        "# test dataloader\n",
        "\n",
        "test_text = range(50)\n",
        "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
        "\n",
        "data_iter = iter(t_loader)\n",
        "sample_x, sample_y = data_iter.next()\n",
        "\n",
        "print(sample_x.shape)\n",
        "print(sample_x)\n",
        "print()\n",
        "print(sample_y.shape)\n",
        "print(sample_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 5])\n",
            "tensor([[39, 40, 41, 42, 43],\n",
            "        [42, 43, 44, 45, 46],\n",
            "        [36, 37, 38, 39, 40],\n",
            "        [ 4,  5,  6,  7,  8],\n",
            "        [13, 14, 15, 16, 17],\n",
            "        [44, 45, 46, 47, 48],\n",
            "        [ 1,  2,  3,  4,  5],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [11, 12, 13, 14, 15],\n",
            "        [14, 15, 16, 17, 18]])\n",
            "\n",
            "torch.Size([10])\n",
            "tensor([44, 47, 41,  9, 18, 49,  6, 10, 16, 19])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzPHoSPc3bV0",
        "colab_type": "text"
      },
      "source": [
        "# Talking Points Model\n",
        "\n",
        "## Genral Architecture\n",
        "\n",
        "### Embedding Layer\n",
        "\n",
        "The model should take our word tokens and firstly pass it through our embedding layer. This layer will be responsible for converting out word tokens or integers into embeddings of specific size. These word embeddings are then fed to the next layer of LSTM cells. <br>\n",
        "\n",
        "The main purpose of using embedding layer is dimensionality reduction.\n",
        "\n",
        "### Contiguous LSTM Layer\n",
        "\n",
        "Our LSTM layer is defined by *hidden state size and number of layers*. At each step, an LSTM cell will produce an output and a new hidden state. The hidden state will be passed to next cell as input (memory representation.)\n",
        "\n",
        "### Final Fully Connected Linear Layer\n",
        "\n",
        "The output generated by LSTM cell will be then fed into a *Sigmoid activated fully-connected linear layer.* This layer is responsible for mapping LSTM output to desired output size.\n",
        "\n",
        "The output of the sigmoid function will be the probability distribution of most likely next word.<br><br>\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Talking Points Model.png?raw=1\" height=\"500\"></img>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsGAqMS52E3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the PyTorch RNN Module\n",
        "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
        "        :param output_size: The number of output dimensions of the neural network\n",
        "        :param embedding_dim: The size of embeddings, should you choose to use them        \n",
        "        :param hidden_dim: The size of the hidden layer outputs\n",
        "        :param dropout: dropout to add in between LSTM/GRU layers\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        # TODO: Implement function\n",
        "        \n",
        "        # define embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # define lstm layer\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=dropout, batch_first=True)\n",
        "        \n",
        "        \n",
        "        # set class variables\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_size = output_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        # define model layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    \n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Forward propagation of the neural network\n",
        "        :param nn_input: The input to the neural network\n",
        "        :param hidden: The hidden state        \n",
        "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
        "        \"\"\"\n",
        "        # TODO: Implement function   \n",
        "        batch_size = x.size(0)\n",
        "        x=x.long()\n",
        "        \n",
        "        # embedding and lstm_out \n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        \n",
        "        # stack up lstm layers\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout, fc layer and final sigmoid layer\n",
        "        out = self.fc(lstm_out)\n",
        "        \n",
        "        # reshaping out layer to batch_size * seq_length * output_size\n",
        "        out = out.view(batch_size, -1, self.output_size)\n",
        "        \n",
        "        # return last batch\n",
        "        out = out[:, -1]\n",
        "\n",
        "        # return one batch of output word scores and the hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        '''\n",
        "        Initialize the hidden state of an LSTM/GRU\n",
        "        :param batch_size: The batch_size of the hidden state\n",
        "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
        "        '''\n",
        "        # create 2 new zero tensors of size n_layers * batch_size * hidden_dim\n",
        "        weights = next(self.parameters()).data\n",
        "        if(train_on_gpu):\n",
        "            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(), \n",
        "                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        # initialize hidden state with zero weights, and move to GPU if available\n",
        "        \n",
        "        return hidden\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UURpsD-g2ciF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
        "    \"\"\"\n",
        "    Forward and backward propagation on the neural network\n",
        "    :param decoder: The PyTorch Module that holds the neural network\n",
        "    :param decoder_optimizer: The PyTorch optimizer for the neural network\n",
        "    :param criterion: The PyTorch loss function\n",
        "    :param inp: A batch of input to the neural network\n",
        "    :param target: The target output for the batch of input\n",
        "    :return: The loss and the latest hidden state Tensor\n",
        "    \"\"\"\n",
        "    \n",
        "    # TODO: Implement Function\n",
        "    \n",
        "    # move data to GPU, if available\n",
        "    if(train_on_gpu):\n",
        "        rnn.cuda()\n",
        "    \n",
        "    # creating variables for hidden state to prevent back-propagation\n",
        "    # of historical states \n",
        "    h = tuple([each.data for each in hidden])\n",
        "    \n",
        "    rnn.zero_grad()\n",
        "    # move inputs, targets to GPU \n",
        "    if(train_on_gpu):\n",
        "        inputs, targets = inp.cuda(), target.cuda()\n",
        "    \n",
        "    output, h = rnn(inputs, h)\n",
        "    \n",
        "    loss = criterion(output, targets)\n",
        "    \n",
        "    # perform backpropagation and optimization\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(rnn.parameters(), 5)\n",
        "    optimizer.step()\n",
        "\n",
        "    # return the loss over a batch and the hidden state produced by our model\n",
        "    return loss.item(), h\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5knZB_P2rqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "\n",
        "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
        "    batch_losses = []\n",
        "    \n",
        "    rnn.train()\n",
        "\n",
        "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
        "    for epoch_i in range(1, n_epochs + 1):\n",
        "        \n",
        "        # initialize hidden state\n",
        "        hidden = rnn.init_hidden(batch_size)\n",
        "        \n",
        "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
        "            \n",
        "            # make sure you iterate over completely full batches, only\n",
        "            n_batches = len(train_loader.dataset)//batch_size\n",
        "            if(batch_i > n_batches):\n",
        "                break\n",
        "            \n",
        "            # forward, back prop\n",
        "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
        "            # record loss\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "            # printing loss stats\n",
        "            if batch_i % show_every_n_batches == 0:\n",
        "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
        "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
        "                batch_losses = []\n",
        "\n",
        "    # returns a trained rnn\n",
        "    return rnn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qhdC7oO2wyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data params\n",
        "# Sequence Length\n",
        "sequence_length = 10  # of words in a sequence\n",
        "# Batch Size\n",
        "batch_size = 128\n",
        "\n",
        "# data loader - do not change\n",
        "train_loader = batch_data(int_text, sequence_length, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4aiXhBi20wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "# Number of Epochs\n",
        "num_epochs = 10\n",
        "# Learning Rate\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Model parameters\n",
        "# Vocab size\n",
        "vocab_size = len(vocab_to_int)\n",
        "# Output size\n",
        "output_size = vocab_size\n",
        "# Embedding Dimension\n",
        "embedding_dim = 200\n",
        "# Hidden Dimension\n",
        "hidden_dim = 250\n",
        "# Number of RNN Layers\n",
        "n_layers = 2\n",
        "\n",
        "# Show stats for every n number of batches\n",
        "show_every_n_batches = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrFjAYqe229y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL\n",
        "\"\"\"\n",
        "\n",
        "# create model and move to gpu if available\n",
        "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.5)\n",
        "if train_on_gpu:\n",
        "    rnn.cuda()\n",
        "\n",
        "# defining loss and optimization functions for training\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# training the model\n",
        "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, 5, show_every_n_batches)\n",
        "\n",
        "# saving the trained model\n",
        "save_model('./save/trained_rnn', trained_rnn)\n",
        "print('Model Trained and Saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMRGOJPW28pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
        "    \"\"\"\n",
        "    Generate text using the neural network\n",
        "    :param decoder: The PyTorch Module that holds the trained neural network\n",
        "    :param prime_id: The word id to start the first prediction\n",
        "    :param int_to_vocab: Dict of word id keys to word values\n",
        "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
        "    :param pad_value: The value used to pad a sequence\n",
        "    :param predict_len: The length of text to generate\n",
        "    :return: The generated text\n",
        "    \"\"\"\n",
        "    rnn.eval()\n",
        "    \n",
        "    # create a sequence (batch_size=1) with the prime_id\n",
        "    current_seq = np.full((1, sequence_length), pad_value)\n",
        "    current_seq[-1][-1] = prime_id\n",
        "    predicted = [int_to_vocab[prime_id]]\n",
        "    \n",
        "    for _ in range(predict_len):\n",
        "        if train_on_gpu:\n",
        "            current_seq = torch.LongTensor(current_seq).cuda()\n",
        "        else:\n",
        "            current_seq = torch.LongTensor(current_seq)\n",
        "        \n",
        "        # initialize the hidden state\n",
        "        hidden = rnn.init_hidden(current_seq.size(0))\n",
        "        \n",
        "        # get the output of the rnn\n",
        "        output, _ = rnn(current_seq, hidden)\n",
        "        \n",
        "        # get the next word probabilities\n",
        "        p = F.softmax(output, dim=1).data\n",
        "        if(train_on_gpu):\n",
        "            p = p.cpu() # move to cpu\n",
        "         \n",
        "        # use top_k sampling to get the index of the next word\n",
        "        top_k = 5\n",
        "        p, top_i = p.topk(top_k)\n",
        "        top_i = top_i.numpy().squeeze()\n",
        "        \n",
        "        # select the likely next word index with some element of randomness\n",
        "        p = p.numpy().squeeze()\n",
        "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
        "        \n",
        "        # retrieve that word from the dictionary\n",
        "        word = int_to_vocab[word_i]\n",
        "        predicted.append(word)     \n",
        "        \n",
        "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
        "        current_seq = np.roll(current_seq.cpu(), -1, 1)\n",
        "        current_seq[-1][-1] = word_i\n",
        "    \n",
        "    gen_sentences = ' '.join(predicted)\n",
        "    \n",
        "    # Replace punctuation tokens\n",
        "    for key, token in token_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
        "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
        "    gen_sentences = gen_sentences.replace('( ', '(')\n",
        "    \n",
        "    # return all the sentences\n",
        "    return gen_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgx8qAcXKXu_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "06fb4917-acc3-4657-be41-d39984c3d8a6"
      },
      "source": [
        "# run the cell multiple times to get different results!\n",
        "gen_length = 100 # modify the length to your preference\n",
        "prime_word = 'corona' # name for starting the script\n",
        "\n",
        "\"\"\"\n",
        "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
        "\"\"\"\n",
        "# def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
        "pad_word = SPECIAL_WORDS['PADDING']\n",
        "generated_script = generate(trained_rnn, vocab_to_int[prime_word], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
        "print(generated_script)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corona. m. est\n",
            "** the dollar slipped 0. 2 percent to 3. 5 percent.\n",
            "in the past decade, the dow jones industrial average was up 0. 2 percent at $1, 326. 00 a barrel.\n",
            "a weaker u. s. dollar slipped from a basket of major currencies in 2018.\n",
            "the dow jones industrial average index was down 0. 3 percent to the lowest level in the past five months, ” the official said.\n",
            "the ministry is not immediately available to comment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm9WwDDBDgFh",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis on Stock Data\n",
        "\n",
        "Sentiment analysis on stock data can be added to one's advantage. If you look for an extreme example of how social media influences stock market, take a look at Elon Musk's tweet about Tesla's stock. <br>\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Elon_musk_tesla.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "Shortly after the message was posted online, within hours, Tesla's market value **crashed by 14 billion dollars** and Musk's own stake in the company reportedly **fell by $3 billion.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc8xeQO8AqEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://drive.google.com/file/d/14hxhKgpoZTODy1B2BHTam23WYXiX4YL5/view?usp=sharing\n",
        "\n",
        "!pip install PyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4FLpWEJBy1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMe32GKkBeYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5C-FUFxBTnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "download = drive.CreateFile({'id': '14hxhKgpoZTODy1B2BHTam23WYXiX4YL5'})\n",
        "download.GetContentFile('dataset.zip')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0EGcuTqlIrf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "956a3504-0644-4585-9b59-b838a7155eab"
      },
      "source": [
        "!unzip dataset"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "   creating: data/\n",
            "  inflating: data/labels.txt         \n",
            "  inflating: __MACOSX/data/._labels.txt  \n",
            "  inflating: data/reviews.txt        \n",
            "  inflating: __MACOSX/data/._reviews.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "091OJ7rxKqWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "reviews = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "#read data from text files\n",
        "with open('./data/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('./data/labels.txt', 'r') as f:\n",
        "    labels = f.read()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIb4h6WwDcWJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "e0bf7b99-bd27-4fc7-bff1-aa396b763d3b"
      },
      "source": [
        "print(reviews[:2000])\n",
        "print()\n",
        "print(labels[:20])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \n",
            "homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y\n",
            "\n",
            "positive\n",
            "negative\n",
            "po\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cycD2oGH9b43",
        "colab_type": "text"
      },
      "source": [
        "## Data pre-processing\n",
        "\n",
        "The first step when building a neural network model is getting your data into the proper form to feed into the network. Since we're using embedding layers, we'll need to encode each word with an integer. We'll also want to clean it up a bit.\n",
        "\n",
        "You can see an example of the reviews data above. Here are the processing steps, we'll want to take:\n",
        ">* We'll want to get rid of periods and extraneous punctuation.\n",
        "* Also, you might notice that the reviews are delimited with newline characters `\\n`. To deal with those, I'm going to split the text into each review using `\\n` as the delimiter. \n",
        "* Then I can combined all the reviews back together into one big string.\n",
        "\n",
        "First, let's remove all punctuation. Then get all the text without the newlines and split it into individual words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfil9uX4Dm9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad0810f4-a8a8-47ff-bc01-51783648003c"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "print(punctuation)\n",
        "\n",
        "# get rid of punctuation\n",
        "reviews = reviews.lower() # lowercase, standardize\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL-Fm_ADDoam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4GCW5ykDomJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "4aee21f8-d6b0-419e-f759-6b8df3a068bc"
      },
      "source": [
        "words[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bromwell',\n",
              " 'high',\n",
              " 'is',\n",
              " 'a',\n",
              " 'cartoon',\n",
              " 'comedy',\n",
              " 'it',\n",
              " 'ran',\n",
              " 'at',\n",
              " 'the',\n",
              " 'same',\n",
              " 'time',\n",
              " 'as',\n",
              " 'some',\n",
              " 'other',\n",
              " 'programs',\n",
              " 'about',\n",
              " 'school',\n",
              " 'life',\n",
              " 'such',\n",
              " 'as',\n",
              " 'teachers',\n",
              " 'my',\n",
              " 'years',\n",
              " 'in',\n",
              " 'the',\n",
              " 'teaching',\n",
              " 'profession',\n",
              " 'lead',\n",
              " 'me']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN366ENf9kgR",
        "colab_type": "text"
      },
      "source": [
        "### Encoding the words\n",
        "\n",
        "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then we can convert each of our reviews into integers so they can be passed into the network.\n",
        "\n",
        "> We will now encode the words with integers. Build a dictionary that maps words to integers. Later we're going to pad our input vectors with zeros, so make sure the integers **start at 1, not 0**.\n",
        "> Also, convert the reviews to integers and store the reviews in a new list called `reviews_ints`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_h43eB7Dopd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq9P1yLiDotp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "583eb661-e3f2-4262-c7ce-006169be0d97"
      },
      "source": [
        "reviews_int = []\n",
        "'''\n",
        "reviews_split contains multiple reviews \n",
        "reviews_int will be 2-D array\n",
        "'''\n",
        "for review in reviews_split:\n",
        "  reviews_int.append([vocab_to_int[word] for word in review.split()])\n",
        "print(len(vocab_to_int))\n",
        "print(reviews_int[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74072\n",
            "[[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23], [63, 4, 3, 125, 36, 47, 7472, 1395, 16, 3, 4181, 505, 45, 17, 3, 622, 134, 12, 6, 3, 1279, 457, 4, 1721, 207, 3, 10624, 7373, 300, 6, 667, 83, 35, 2116, 1086, 2989, 34, 1, 898, 46417, 4, 8, 13, 5096, 464, 8, 2656, 1721, 1, 221, 57, 17, 58, 794, 1297, 832, 228, 8, 43, 98, 123, 1469, 59, 147, 38, 1, 963, 142, 29, 667, 123, 1, 13584, 410, 61, 94, 1774, 306, 755, 5, 3, 819, 10396, 22, 3, 1724, 635, 8, 13, 128, 73, 21, 233, 102, 17, 49, 50, 617, 34, 682, 85, 28785, 28786, 682, 374, 3341, 11398, 2, 16371, 7946, 51, 29, 108, 3324], [22382, 42, 46418, 15, 706, 17139, 3389, 47, 77, 35, 1819, 16, 154, 19, 114, 3, 1305, 5, 336, 147, 22, 1, 857, 12, 70, 281, 1168, 399, 36, 120, 283, 38, 169, 5, 382, 158, 42, 2269, 16, 1, 541, 90, 78, 102, 4, 1, 3244, 15, 43, 3, 407, 1068, 136, 8055, 44, 182, 140, 15, 3043, 1, 320, 22, 4818, 26224, 346, 5, 3090, 2092, 1, 18839, 17939, 42, 8055, 46, 33, 236, 29, 370, 5, 130, 56, 22, 1, 1928, 7, 7, 19, 48, 46, 21, 70, 344, 3, 2099, 5, 408, 22, 1, 1928, 16, 3, 3119, 205, 1, 28787, 21, 281, 68, 38, 3, 339, 1, 700, 715, 3, 3818, 1229, 22, 1, 1491, 3, 1197, 2, 283, 21, 281, 2435, 5, 66, 48, 8, 13, 39, 5, 29, 3244, 12, 6, 21026, 11723, 13, 2015, 7, 7, 3687, 2818, 36, 4147, 36, 374, 15, 11723, 296, 3, 996, 125, 36, 47, 283, 9, 1, 176, 363, 6893, 5, 94, 3, 2099, 17, 3, 4976, 2932, 14557, 19870, 5, 66, 46, 25, 51, 408, 9, 1, 1928, 16, 3236, 490, 205, 1, 28787, 46, 11723, 2845, 25, 51, 80, 48, 25, 483, 17, 3, 682, 1148, 4, 228, 52, 4461, 1, 2099, 13, 22, 118, 11723, 6, 1347, 22, 1, 857, 17, 3, 18840, 22, 27, 3873, 5, 10167, 27, 174, 829, 118, 25, 51, 23, 1456, 123, 1, 6451, 25, 13, 344, 1, 13585, 28788, 34, 3, 32300, 101, 8, 13, 391, 22, 27, 11724, 118, 11723, 874, 81, 103, 577, 3, 240, 34, 1, 393, 4, 4653, 16372, 1816, 3737, 35, 1200, 3103, 36, 188, 4048, 160, 2284, 41, 339, 2, 41, 8809, 6793, 1984, 4313, 2, 28789, 8810, 2457, 36, 26, 453, 338, 5, 1, 1928, 33, 155, 4219, 11723, 215, 23, 25, 13, 24, 338, 5, 4421, 5903, 28790, 39, 25, 281, 120, 54, 111, 996, 118, 8, 13, 534, 42, 2718, 501, 42, 29, 547, 7, 7, 136, 1, 115, 2003, 198, 4653, 2, 11723, 285, 23, 1644, 5, 112, 10, 254, 110, 4354, 5, 29, 30, 4, 3687, 2818, 15686, 107, 118, 2523, 5, 111, 3, 207, 8, 286, 3, 4220, 488, 1060, 5, 27, 2730, 158, 140, 15, 7473, 11399, 184, 4539, 42, 18841, 16, 1, 541, 5, 121, 48, 8, 13, 39, 255, 141, 4504, 160, 2284, 8, 1, 370, 245, 42, 22, 1, 81, 495, 228, 3, 372, 2099, 39, 31, 996, 78, 80, 54, 33, 89, 23, 122, 48, 5, 80, 17, 67, 273, 277, 33, 142, 200, 8, 5, 1, 3244, 303, 4, 757, 8, 39, 17140, 273, 7, 7, 42, 277, 11, 20, 79, 5853, 21, 5, 336, 400], [4505, 505, 15, 3, 3342, 162, 8312, 1652, 6, 4819, 56, 17, 4504, 5616, 140, 11725, 5, 996, 4919, 2933, 4462, 566, 1201, 36, 6, 1518, 96, 3, 744, 4, 26225, 13, 5, 27, 3461, 9, 10625, 4, 8, 111, 3013, 5, 1, 1027, 15, 3, 4390, 82, 22, 2049, 6, 4462, 538, 2764, 7073, 37443, 41, 463, 1, 8312, 46419, 302, 123, 15, 4221, 19, 1667, 922, 1, 1652, 6, 6129, 19871, 34, 1, 980, 1751, 22383, 646, 24104, 27, 106, 11726, 13, 14045, 15097, 17940, 2457, 466, 21027, 36, 3266, 1, 6365, 1020, 45, 17, 2695, 2499, 33, 1305, 5, 2076, 1, 4504, 11727, 1493, 22, 3, 21028, 1652, 3196, 22, 35, 4314, 1067, 19, 136, 228, 27, 4654, 22383, 217, 1906, 35, 3216, 17141, 9, 1, 4148, 1961, 1110, 4, 1, 1652, 5617, 8, 6524, 83, 1, 1958, 118, 8, 8056, 5, 1, 1301, 204, 3985, 9, 1, 641, 4, 1, 32301, 5854, 17, 922, 9, 342, 6200, 1047, 28791, 9, 255, 15687, 119, 1985, 123, 259, 1, 695, 12046, 16, 1, 4820, 13, 15, 33, 12397, 336, 17, 57, 688, 608, 45, 7, 7, 82, 560, 458, 1, 1056, 271, 28792, 4505, 11, 330, 736, 5, 1, 6702, 557, 1661, 689, 4505, 14, 516, 34, 1435, 9121, 136, 281, 173, 39, 8, 13, 8313, 10, 51, 23, 133, 4505, 6, 100, 428, 4, 1527, 349, 8, 6, 440, 256, 24, 2686, 16, 1, 204, 987, 45, 4, 1, 287, 4505, 107, 10, 28, 108, 37, 227, 10, 165, 418, 11, 30, 1, 117, 43, 8, 47, 60, 1621, 112, 4, 1, 287, 17, 3, 324, 1667, 922, 6129, 32302, 93, 1, 6524, 161, 23, 25, 66, 1, 3216, 17141, 6201, 4, 1, 277, 1, 1154, 70, 264, 5, 1638, 1, 201, 4505, 17, 159, 1043, 1661, 494, 4, 1, 791, 1, 32303, 1115, 18842, 6, 118, 8, 2656, 363, 1, 130, 17, 3, 5245, 6287, 4391, 147, 2582, 982, 343, 37444, 54, 1, 922, 1106, 45, 42, 10878, 15, 1, 24105, 42, 46, 100, 4, 1, 3529, 26, 3013, 8, 13, 3, 531, 322, 12, 97, 28, 91, 16, 3, 85, 116, 1661, 494, 19, 76, 6794, 104, 13, 739, 410, 12047, 265, 1298, 3, 146, 574, 4, 2327, 42, 817, 42, 1054, 800, 11, 6, 3, 1026, 1400, 136, 1, 246, 12767, 112, 918, 30, 2144, 16, 1006, 229, 24, 12, 74, 559, 101, 1, 1652, 8056, 40, 13, 24, 15, 74, 8811, 15, 10, 195, 40, 142, 28, 77, 59, 54, 1, 2914, 409, 562, 182, 89, 23, 1236, 56, 12, 74, 17, 3, 170, 648, 4, 653, 5097, 10626, 1518, 44, 19, 40, 13, 43, 141, 1867, 127, 706, 4015, 15, 1, 37445, 12048, 3444, 865, 37446, 6, 144, 19, 64, 211, 3, 368, 4, 137, 1176, 59, 549, 231, 16373, 5, 43, 167, 3738, 9, 1, 958, 7, 7, 1, 339, 366, 2220, 310, 4, 4505, 506, 229, 136, 1, 178, 242, 2033, 747, 35, 1685, 522, 4, 908, 577, 3, 162, 622, 878, 702, 109, 52, 137, 17, 706, 4015, 15, 37446, 2123, 5, 2077, 45, 104, 13, 1184, 2196, 137, 1, 3766, 42, 159, 368, 4, 340, 2306, 577, 1, 32304, 136, 10, 61, 39, 5, 66, 11, 1685, 908, 10, 239, 24, 249, 10, 97, 848, 145, 3, 733, 287, 522, 584, 4, 4505, 15, 853, 1, 20, 47, 1936, 889, 17, 517, 7818, 7374, 1571, 2800, 10, 79, 133, 58, 52, 81, 73, 1, 2819, 1652, 2117, 298, 696, 23, 85, 343, 364, 17, 1, 81, 106, 4505, 2256, 11, 302, 3076, 4, 269, 9, 1, 10627, 1315, 13, 2280, 4, 879, 256, 10, 51, 102, 4, 760, 4, 429, 107, 73, 11, 37, 10, 10879, 12, 13, 3, 116, 2458, 1, 202, 137, 26, 3, 116, 739, 464, 1, 1040, 6, 539, 24, 74, 2285, 42, 1054, 6, 4821, 62, 6, 3, 879, 15, 10, 10879, 11, 97, 28, 77, 3, 183, 50, 20, 46, 91, 2846, 7, 7, 1, 360, 1205, 26, 2626, 46, 163, 2068, 1, 113, 215, 23, 85, 106, 57, 708, 2186, 669, 3949, 47, 301, 234, 8, 14, 3, 1293, 5, 318, 9, 11, 30, 57, 708, 2186, 566, 1201, 268, 153, 11118, 82, 30, 57, 708, 2186, 743, 1968, 268, 1793, 136, 2642, 1331, 743, 6, 344, 116, 5, 80, 40, 26, 934, 4, 81, 1061, 1562, 5, 167, 45, 16, 98, 7, 7, 4505, 6, 1, 90, 1661, 21029, 4, 1, 287, 4505, 107, 37, 227, 10, 418, 1, 989, 485, 8, 59, 46, 33, 70, 3, 223, 694, 1, 360, 1889, 451, 151, 23, 336, 150, 3, 20, 44, 3, 15688, 1652, 43, 1587, 23, 29, 11, 354, 42, 12047, 1457, 34, 1, 22384, 4505], [520, 119, 113, 34, 16372, 1816, 3737, 117, 885, 21030, 721, 10, 28, 124, 108, 2, 115, 137, 9, 1623, 7691, 26, 330, 5, 589, 1, 6130, 22, 386, 6, 3, 349, 15, 50, 15, 231, 9, 7473, 11399, 1, 191, 22, 8966, 6, 82, 880, 101, 111, 3584, 4, 111, 3, 28793, 3445, 45, 27, 1324, 2, 111, 12398, 1, 2360, 4, 28788, 11723, 24106, 32305, 10, 143, 3, 2360, 25, 549, 287, 164, 697, 4016, 19870, 3, 502, 38, 1, 299, 2643, 6525, 121, 6, 759, 127, 98, 15, 3, 1135, 5098, 36, 483, 5, 4182, 1, 6608, 27, 104, 6, 52, 10397, 73, 630, 1, 1519, 134, 2, 1, 134, 118, 1, 3244, 17142, 3, 14046, 2100, 26, 31, 57, 2179, 167, 16, 1, 2951, 134, 2, 1, 106, 192, 15689, 975, 30, 24107, 11, 18, 211, 128, 253, 57, 10, 66, 8, 62, 6, 179, 395], [11, 20, 3637, 141, 10, 422, 23, 272, 60, 4355, 22, 32, 84, 3286, 22, 1, 172, 4, 1, 952, 507, 11, 4977, 5361, 5, 574, 4, 1155, 54, 53, 5304, 1, 261, 17, 41, 952, 125, 59, 1, 711, 137, 379, 626, 15, 111, 1509, 1, 156, 32, 292, 8, 97, 55, 72, 28, 77, 1, 157, 36, 37447, 48, 25, 871, 38, 1, 156, 10, 43, 89, 23, 122, 7, 7, 19, 97, 8, 28, 77, 1, 860, 43, 605, 36, 14, 1, 8812, 9, 115, 17, 25, 460, 52, 15098, 4, 27, 28794, 1937, 2, 3688, 2, 1092, 4, 309, 2, 27, 6131, 6056, 73, 4, 1702, 42, 231, 326, 25, 114, 2312, 71, 25, 14, 9, 115, 17, 1, 2484, 7, 7, 10, 14, 672, 9, 11, 18, 19, 89, 23, 836, 8, 14, 2270, 16, 35, 708, 37, 1857, 16, 610], [11, 6, 692, 1, 90, 2156, 20, 11728, 1, 2818, 5195, 249, 92, 3006, 8, 126, 24, 200, 3, 802, 634, 4, 22382, 1001, 133, 87, 3530, 3343, 509, 3, 802, 634, 4, 16374, 5096, 42, 2552, 509, 3, 802, 634, 4, 8967, 21, 3709, 109, 4, 1, 623, 787, 1010, 19, 131, 11, 20, 6, 55, 3178, 9, 3, 95, 109, 1258, 26, 24, 2, 5, 1572, 12, 123, 9, 3, 63, 44, 49, 4, 1, 90, 11729, 22385, 1039, 4, 875, 6, 365, 1132, 92, 24, 1, 3446, 607, 19, 92, 24, 582, 343, 60, 64, 3267, 6, 12, 2818, 142, 28, 177, 279, 326, 9, 1, 475, 10, 115, 3687, 15, 3, 157, 2, 533, 24, 37, 74, 15, 3, 475], [786, 295, 10, 122, 11, 6, 419, 5, 29, 35, 482, 20, 19, 1281, 33, 142, 28, 2657, 45, 1840, 32, 1, 2778, 37, 78, 97, 2436, 67, 3950, 45, 2, 24, 105, 256, 1, 134, 1571, 2, 12399, 451, 14, 319, 11, 63, 6, 98, 1321, 5, 105, 1, 3767, 4, 3, 472, 1381, 14, 1736, 1, 46420, 648, 70, 98, 194, 87, 194, 51, 21, 105, 106, 78, 43, 1238, 40, 2, 642, 257, 54, 1, 410, 6, 106, 78, 5246, 10, 65, 68, 3, 250, 57, 43, 390, 145, 11, 20, 1, 351, 70, 319, 19, 87, 74, 4, 12, 454, 14558, 3585, 529, 51, 21, 191, 1, 64, 152, 10, 418, 14, 7074, 14559, 2, 41, 737, 2670, 2, 1073, 134, 881, 11, 14, 3, 7474, 4, 4392, 2, 10, 143, 58, 331, 1311, 27, 343, 10, 102, 251, 36, 549, 33, 499, 620, 4, 11, 6, 72, 3148], [11, 6, 24, 1, 779, 3687, 2818, 20, 8, 14, 74, 325, 2730, 73, 90, 4, 27, 99, 2, 165, 68, 3, 112, 12, 14, 28795, 2779, 1816, 3737, 91, 1, 18, 53, 6, 140, 3, 759, 458, 1124, 507, 40, 70, 49, 381, 12, 97, 28, 77, 6526, 45, 3, 223, 52, 2, 49, 137, 12, 97, 238, 28, 77, 584, 5, 94, 1, 654, 5, 80, 37, 19, 31, 9, 31, 11, 6, 288, 1, 1783, 5, 831, 2, 66, 8, 1, 113, 14, 50, 442, 2818, 309, 120, 3, 50, 289, 205, 27, 7576, 1362, 5, 2514, 5, 1, 300, 173, 3737, 14, 1, 117, 270, 9, 1, 18, 19, 37448, 2, 6793, 197, 252, 67, 521, 72], [54, 10, 14, 116, 60, 798, 552, 71, 364, 5, 1, 730, 5, 66, 8057, 8, 14, 30, 4, 109, 99, 10, 293, 17, 60, 798, 19, 11, 14, 1, 64, 30, 69, 2500, 45, 4, 234, 93, 10, 68, 114, 108, 8057, 363, 43, 1009, 2, 10, 97, 28, 1431, 45, 1, 357, 4, 60, 110, 205, 8, 48, 3, 1929, 10880, 2, 2124, 354, 412, 4, 13, 6609, 2, 2974, 5148, 2125, 1366, 6, 30, 4, 60, 502, 876, 19, 8057, 6, 34, 227, 1, 247, 412, 4, 582, 4, 27, 599, 9, 1, 13586, 396, 4, 14047, 16375, 1366, 403, 178, 3, 454, 21031, 8968, 2601, 9, 5, 1, 450, 4, 3, 212, 11730, 34, 1, 1946, 3986, 2145, 34, 4048, 22386, 599, 115, 683, 115, 46421, 824, 1, 20, 4607, 47, 58, 680, 2113, 58, 224, 2, 6, 14048, 9, 9505, 6795, 11, 20, 396, 51, 29, 117, 4741, 15, 12768, 9, 849, 757, 35, 24108, 4149, 4, 410, 5, 14049, 3, 52, 9924, 1111, 4, 1191, 2, 854, 19, 2125, 1366, 6, 58, 14047, 4392, 1, 20, 6, 2124, 539, 2, 739, 19, 705, 12, 10, 328, 68, 58, 2003, 17, 42, 2467, 16, 100, 4, 1, 103, 303, 10, 416, 64, 5974, 16, 11, 5149, 4, 17941, 6527, 28796, 15690, 28797, 9, 3, 11731, 2644, 16, 2016, 8314, 3, 4078, 4, 22387, 37449, 2, 8058, 37450, 28798, 1, 63, 19872, 39, 3, 7375, 9, 1, 654, 295, 2437, 9, 3844, 16376, 2, 10881, 1074, 198, 10882, 295, 6, 407, 2, 2485, 1645, 5, 168, 451, 42, 1879, 42, 824, 2, 8, 43, 266, 22, 2, 22, 5, 1, 210, 118, 21, 43, 181, 5, 3606, 31, 4, 96, 8, 13, 114, 44, 3429, 8, 13, 64, 44, 9696, 13587, 13154, 8, 6, 163, 52, 73, 3, 1946, 448, 614, 5, 35, 1539, 705, 1, 300, 13, 1230, 5, 3739, 2125, 1366, 2438, 5, 94, 103, 37, 9320, 9, 525, 69, 230, 313, 45, 2, 16, 12, 284, 10, 254, 11, 18, 2124, 524, 5050, 2, 17942, 13588, 10, 66, 48, 25, 14, 169, 16, 19, 27, 13155, 22, 8485, 27, 729, 145, 24109, 15691, 2, 8178, 20, 3325, 32306, 8, 491, 1, 210, 4, 7075, 10, 535, 380, 11, 30, 46, 21, 155, 537, 3, 116, 98, 631, 2, 355, 141, 5, 2988, 21, 4, 333, 881, 278, 13, 43, 3874, 11, 20, 114, 563]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR4J17duDow3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "08af0a77-fab3-4ae2-8d2e-2db8931a337e"
      },
      "source": [
        "# stats about vocabulary\n",
        "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
        "print()\n",
        "\n",
        "# print tokens in first review\n",
        "print('Tokenized review: \\n', reviews_int[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words:  74072\n",
            "\n",
            "Tokenized review: \n",
            " [[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnWkHlyYDozz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "460a40c4-dffc-4c0d-fd6c-191c96c775b0"
      },
      "source": [
        "labels_split = labels.split('\\n')\n",
        "labels_to_int = np.array([1 if label=='positive' else 0 for label in labels_split])\n",
        "\n",
        "zero_length_reviews = Counter([len(x) for x in reviews_int])\n",
        "print(max(zero_length_reviews))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdBviRlyDo2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "38a58635-5da1-4bf3-c8f4-8361bda39862"
      },
      "source": [
        "# outlier review stats\n",
        "review_lens = Counter([len(x) for x in reviews_int])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 1\n",
            "Maximum review length: 2514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3B5RTGlmWdL",
        "colab_type": "text"
      },
      "source": [
        "### Removing Outliers\n",
        "\n",
        "As an additional pre-processing step, we want to make sure that our reviews are in good shape for standard processing. That is, our network will expect a standard input text size, and so, we'll want to shape our reviews into a specific length. We'll approach this task in two main steps:\n",
        "\n",
        "1. Getting rid of extremely long or short reviews; the outliers\n",
        "2. Padding/truncating the remaining data so that we have reviews of the same length.\n",
        "\n",
        "Before we pad our review text, we should check for reviews of extremely short or long lengths; outliers that may mess with our training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENcAXvlPDo50",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d2c574c-ba23-4c38-8848-0fe94401c946"
      },
      "source": [
        "print('Number of reviews before removing outliers: ', len(reviews_int))\n",
        "\n",
        "## remove any reviews/labels with zero length from the reviews_ints list.\n",
        "\n",
        "non_zero_idx = [ii for ii, review in enumerate(reviews_int) if len(review)!=0]\n",
        "reviews_int = [reviews_int[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])\n",
        "\n",
        "\n",
        "print('Number of reviews after removing outliers: ', len(reviews_int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of reviews before removing outliers:  25001\n",
            "Number of reviews after removing outliers:  25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qC8okBRitPKT",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "## Padding sequences\n",
        "\n",
        "To deal with both short and very long reviews, we'll pad or truncate all our reviews to a specific length. For reviews shorter than some `seq_length`, we'll pad with 0s. For reviews longer than `seq_length`, we can truncate them to the first `seq_length` words. A good `seq_length`, in this case, is 200.\n",
        "\n",
        "> Here, we have defined a function that returns an array `features` that contains the padded data, of a standard size, that we'll pass to the network. \n",
        "* The data should come from `review_ints`, since we want to feed integers to the network. \n",
        "* Each row should be `seq_length` elements long. \n",
        "* For reviews shorter than `seq_length` words, **left pad** with 0s. That is, if the review is `['best', 'movie', 'ever']`, `[117, 18, 128]` as integers, the row will look like `[0, 0, 0, ..., 0, 117, 18, 128]`. \n",
        "* For reviews longer than `seq_length`, use only the first `seq_length` words as the feature vector.\n",
        "\n",
        "As a small example, if the `seq_length=10` and an input review is: \n",
        "```\n",
        "[117, 18, 128]\n",
        "```\n",
        "The resultant, padded sequence should be: \n",
        "\n",
        "```\n",
        "[0, 0, 0, 0, 0, 0, 0, 117, 18, 128]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFs5r83QDo8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_int, seq_length):\n",
        "  features = np.zeros((len(reviews_int), seq_length), dtype=int)\n",
        "  for i, row in enumerate(reviews_int):\n",
        "    features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "  \n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpEfMn6NDpFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test your implementation!\n",
        "\n",
        "seq_length = 200\n",
        "features = pad_features(reviews_int, seq_length)\n",
        "print(features[:30, :10])\n",
        "\n",
        "## test statements - do not change - ##\n",
        "assert len(features)==len(reviews_int), \"Your features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches \n",
        "print(features[:30,:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkQVICT-DpIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADJPzqa2DpLG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure to SHUFFLE your data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xm6W-5THEHuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "20c5a683-73b4-4f9c-f498-c751ba23c243"
      },
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input: \n",
            " tensor([[   10,   254,   131,  ...,    17,    88,     2],\n",
            "        [    0,     0,     0,  ...,     2,   425,  1470],\n",
            "        [   10,    43,  2368,  ...,    12,    40,     6],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,   115,    17,   273],\n",
            "        [   10, 17710,    11,  ...,   277,     1,  1020],\n",
            "        [    0,     0,     0,  ...,    33,    70,  1553]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n",
            "        0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
            "        0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R37SpjO5EH4r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2a6316c-34cc-456b-e423-315b684f640e"
      },
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTBWnW_utgrW",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Sentiment Network with PyTorch\n",
        "\n",
        "Here we define the network.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/purvasingh96/Talking-points-global-hackathon/blob/master/assets/Sentiment%20Analysis%20network.png?raw=1\" width=\"500\"></img>\n",
        "\n",
        "The layers are as follows:\n",
        "1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n",
        "2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n",
        "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
        "4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n",
        "\n",
        "### The Embedding Layer\n",
        "\n",
        "We need to add an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) because there are 74000+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. You could train an embedding layer using Word2Vec, then load it here. But, it's fine to just make a new layer, using it for only dimensionality reduction, and let the network learn the weights.\n",
        "\n",
        "\n",
        "### The LSTM Layer(s)\n",
        "\n",
        "We'll create an [LSTM](https://pytorch.org/docs/stable/nn.html#lstm) to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter.\n",
        "\n",
        "Most of the time, you're network will have better performance with more layers; between 2-3. Adding more layers allows the network to learn really complex relationships. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak0Tt-ZfEH8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "    super(SentimentRNN, self).__init__()\n",
        "\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "    self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    batch_size = x.size(0)\n",
        "    x = x.long()\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "    out = self.dropout(lstm_out)\n",
        "    out = self.fc(out)\n",
        "    sig_out = self.sig(out)\n",
        "\n",
        "    sig_out = sig_out.view(batch_size, -1)\n",
        "    sig_out = sig_out[:, -1]\n",
        "\n",
        "    return sig_out, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "    if(train_on_gpu):\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(), \n",
        "                weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "      hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim), \n",
        "                weight,new(self.n_layers, batch_size, self.hidden_dim))\n",
        "      \n",
        "    return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5pvaU1hEH_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d569dc79-9235-475b-bba8-addcb2624a99"
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hY9m5shaEV94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzmqEmmSEWe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "bafa377f-8762-49f3-861e-8d536f6d0c6b"
      },
      "source": [
        "epochs = 4\n",
        "counter = 0 \n",
        "print_every = 100\n",
        "clip = 5\n",
        "if(train_on_gpu):\n",
        "  net.cuda()\n",
        "\n",
        "net.train()\n",
        "for e in range(epochs):\n",
        "  h = net.init_hidden(batch_size)\n",
        "  for inputs, labels in train_loader:\n",
        "    counter += 1\n",
        "    if(train_on_gpu):\n",
        "      inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    h = tuple([each.data for each in h])\n",
        "    net.zero_grad()\n",
        "    output, h = net(inputs, h)\n",
        "    loss = criterion(output.squeeze(), labels.float())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm(net.parameters(), clip)\n",
        "    optimizer.step()\n",
        "\n",
        "    if counter % print_every == 0:\n",
        "      val_h = net.init_hidden(batch_size)\n",
        "      val_losses = []\n",
        "      net.eval()\n",
        "      for inputs, labels in valid_loader:\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "        if(train_on_gpu):\n",
        "          inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        output, val_h = net(inputs, val_h)\n",
        "        val_loss = criterion(output.squeeze(), labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "      net.train()\n",
        "      print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/4... Step: 100... Loss: 0.693711... Val Loss: 0.653396\n",
            "Epoch: 1/4... Step: 200... Loss: 0.544701... Val Loss: 0.571027\n",
            "Epoch: 1/4... Step: 300... Loss: 0.562405... Val Loss: 0.557840\n",
            "Epoch: 1/4... Step: 400... Loss: 0.646383... Val Loss: 0.633329\n",
            "Epoch: 2/4... Step: 500... Loss: 0.678114... Val Loss: 0.709534\n",
            "Epoch: 2/4... Step: 600... Loss: 0.566871... Val Loss: 0.530177\n",
            "Epoch: 2/4... Step: 700... Loss: 0.494823... Val Loss: 0.530239\n",
            "Epoch: 2/4... Step: 800... Loss: 0.345891... Val Loss: 0.454900\n",
            "Epoch: 3/4... Step: 900... Loss: 0.307721... Val Loss: 0.481526\n",
            "Epoch: 3/4... Step: 1000... Loss: 0.329811... Val Loss: 0.469423\n",
            "Epoch: 3/4... Step: 1100... Loss: 0.299512... Val Loss: 0.490447\n",
            "Epoch: 3/4... Step: 1200... Loss: 0.238392... Val Loss: 0.461704\n",
            "Epoch: 4/4... Step: 1300... Loss: 0.311766... Val Loss: 0.491983\n",
            "Epoch: 4/4... Step: 1400... Loss: 0.336497... Val Loss: 0.480622\n",
            "Epoch: 4/4... Step: 1500... Loss: 0.345086... Val Loss: 0.544988\n",
            "Epoch: 4/4... Step: 1600... Loss: 0.177175... Val Loss: 0.495150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVeU2Nr5EWMI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18dabe36-661f-4e04-a78d-64a02d53bb30"
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.488\n",
            "Test accuracy: 0.812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYITRozZEWKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_movie_review(test_review):\n",
        "  test_review = test_review.lower()\n",
        "  test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "  test_words = test_text.split()\n",
        "  test_ints = []\n",
        "  test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "  return test_ints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVWH6UeaEICD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41eccb91-3cad-4b30-8bbe-57f0e7ac779d"
      },
      "source": [
        "test_review_neg = \"It was a very bad movie. Terrible acting.\"\n",
        "tokenized_review = tokenize_movie_review(test_review_neg)\n",
        "print(tokenize_movie_review(test_review_neg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8, 14, 3, 55, 76, 18, 388, 113]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lbGUaYbElHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "e5425864-6704-43af-8263-8006d6ffa553"
      },
      "source": [
        "seq_length = 200\n",
        "features = pad_features(tokenized_review, seq_length)\n",
        "print(features)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   8  14   3  55  76  18\n",
            "  388 113]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTNB-HOiElSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5005710a-1735-4f87-8c52-35aa0ec4262a"
      },
      "source": [
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtMoZgVLEldD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(net, test_review, seq_length=200):\n",
        "  net.eval()\n",
        "  test_ints = tokenize_movie_review(test_review)\n",
        "  seq_length=seq_length\n",
        "  features = pad_features(test_ints, seq_length)\n",
        "  feature_tensor = torch.from_numpy(features)\n",
        "  batch_size = feature_tensor.size(0)\n",
        "  h = net.init_hidden(batch_size)\n",
        "  if(train_on_gpu):\n",
        "    feature_tensor=feature_tensor.cuda()\n",
        "  output, h = net(feature_tensor, h)\n",
        "  pred = torch.round(output.squeeze())\n",
        "  print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "  if(pred.item()==1):\n",
        "    print(\"Positive\")\n",
        "  else:\n",
        "    print(\"Negative\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLfp5m0gEqeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13de7560-b1c3-41fa-a544-8c6f6c00a2ea"
      },
      "source": [
        "# negative test review\n",
        "test_review_neg = 'Stocks are going down as new corona virus cases surge'\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "\n",
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value, pre-rounding: 0.359334\n",
            "Negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZflNB7-9EqjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5e684fa7-b1ed-4dd7-c526-34155bbf1f3c"
      },
      "source": [
        "# negative test review\n",
        "test_review_neg = 'Stock market is booming and growing post corona pandemic.'\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "\n",
        "predict(net, test_review_neg, seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction value, pre-rounding: 0.717415\n",
            "Positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsnUyAqouEp6",
        "colab_type": "text"
      },
      "source": [
        "# Converting Result into CSV File\n",
        "\n",
        "Finally, we are converting the generated talking points and the corresponding sentiment analysis into a csv file which can be further called from an API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04QVNUP5Eqnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNcY-9LW902j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_talking_points = x.split('.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU2GCptIEqsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "with open('talking_agenda.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"SN\", \"Talking Point\", \"Sentiment Prediction\"])\n",
        "    for i, points in enumerate(generated_talking_points):\n",
        "      sentiment_predicted = predict(net, points, seq_length)\n",
        "      writer.writerow([i, points, sentiment_predicted])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXlSw_2S-kMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}